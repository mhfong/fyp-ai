{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f71caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module, LSTM, Linear\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import yfinance as yf\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ac3f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "\n",
    "    etf = \"QQQ\"\n",
    "    tickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"GOOG\", \"FB\", \"GOOGL\", \"NVDA\", \"PYPL\", \"ADBE\"]\n",
    "\n",
    "    feature_columns = list(range(0,22))\n",
    "    label_columns = [20,21]\n",
    "    label_in_feature_index = (lambda x,y: [x.index(i) for i in y])(feature_columns, label_columns)\n",
    "\n",
    "    predict_day = 1\n",
    "\n",
    "    model_type = \"gru\"\n",
    "    dateset_type = 1\n",
    "    train_data_rate = 0.95\n",
    "\n",
    "    do_train = True\n",
    "    do_predict = True\n",
    "    time_step = 20\n",
    "    valid_data_rate = 0.15\n",
    "    random_seed = 42\n",
    "    shuffle_train_data = True\n",
    "\n",
    "    input_size = len(feature_columns)\n",
    "    output_size = len(label_columns)\n",
    "    hidden_size = 128       \n",
    "    layers = 2\n",
    "    dropout_rate = 0.2\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    epoch = 100\n",
    "    do_continue_train = False\n",
    "    do_train_visualized = False\n",
    "    patience = 5\n",
    "\n",
    "    model_save_path = \"./saved_model/\"\n",
    "    if model_type==\"gru\":\n",
    "        model_name = \"GRU_model.pth\"\n",
    "    elif model_type==\"lstm\":\n",
    "        model_name = \"LSTM_model.pth\"\n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "\n",
    "    data_save_path = \"./dataset/\"\n",
    "    if not os.path.exists(data_save_path):\n",
    "        os.makedirs(data_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "973dadc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = list(range(0,11))\n",
    "label_columns = [10]\n",
    "label_in_feature_index = (lambda x,y: [x.index(i) for i in y])(feature_columns, label_columns)\n",
    "label_in_feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ea802d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data, self.data_column_name = self.read_data()\n",
    "\n",
    "        self.data_num = self.data.shape[0]\n",
    "        self.train_num = int(self.data_num * self.config.train_data_rate)\n",
    "\n",
    "        # Normalization\n",
    "        self.mean = np.mean(self.data, axis=0) \n",
    "        self.std = np.std(self.data, axis=0)\n",
    "        self.norm_data = (self.data - self.mean)/self.std \n",
    "\n",
    "    def read_data(self):\n",
    "        tickers = self.config.tickers\n",
    "        tickers.append(self.config.etf)\n",
    "        ticker_list = yf.Tickers(tickers)\n",
    "        df = {}\n",
    "        for ticker in tickers:\n",
    "            df[ticker+\"_High\"] = ticker_list.tickers[ticker].history(start=\"2016-01-01\")['High']\n",
    "            df[ticker+\"_Low\"] = ticker_list.tickers[ticker].history(start=\"2016-01-01\")['Low']\n",
    "        df = pd.DataFrame(df)\n",
    "        df.to_csv(self.config.data_save_path+\"top10\"+\".csv\")\n",
    "        return df.values, df.columns.tolist()\n",
    "\n",
    "    def get_train_and_valid_data(self):\n",
    "        feature_data = self.norm_data[:self.train_num]\n",
    "        label_data = self.norm_data[self.config.predict_day : self.config.predict_day + self.train_num,\n",
    "                                    self.config.label_in_feature_index]\n",
    "\n",
    "        train_x = [feature_data[start_index + i*self.config.time_step : start_index + (i+1)*self.config.time_step]\n",
    "                        for start_index in range(self.config.time_step)\n",
    "                        for i in range((self.train_num - start_index) // self.config.time_step)]\n",
    "        train_y = [label_data[start_index + i*self.config.time_step : start_index + (i+1)*self.config.time_step]\n",
    "                    for start_index in range(self.config.time_step)\n",
    "                    for i in range((self.train_num - start_index) // self.config.time_step)]\n",
    "\n",
    "        train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, \n",
    "        test_size=self.config.valid_data_rate, random_state=self.config.random_seed, \n",
    "        shuffle=self.config.shuffle_train_data)\n",
    "        \n",
    "        return train_x, valid_x, train_y, valid_y\n",
    "\n",
    "    def get_test_data(self):\n",
    "        feature_data = self.norm_data[self.train_num:]\n",
    "        sample_interval = min(feature_data.shape[0], self.config.time_step)\n",
    "        self.start_num_in_test = feature_data.shape[0] % sample_interval\n",
    "        time_step_size = feature_data.shape[0] // sample_interval\n",
    "\n",
    "        test_x = [feature_data[self.start_num_in_test+i*sample_interval : self.start_num_in_test+(i+1)*sample_interval]\n",
    "                   for i in range(time_step_size)]\n",
    "\n",
    "        return np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fdf683f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "\n",
    "    np.random.seed(config.random_seed)\n",
    "\n",
    "\n",
    "    dataset = Data(config)\n",
    "    \n",
    "\n",
    "    train_X, valid_X, train_Y, valid_Y = dataset.get_train_and_valid_data()\n",
    "    train(config, [train_X, train_Y, valid_X, valid_Y])\n",
    "\n",
    "    test_X = dataset.get_test_data()\n",
    "    pred_result = predict(config, test_X)   \n",
    "    \n",
    "    label_data = dataset.data[dataset.train_num + dataset.start_num_in_test : ,\n",
    "                                            config.label_in_feature_index]\n",
    "    predict_data = pred_result * dataset.std[config.label_in_feature_index] + \\\n",
    "                   dataset.mean[config.label_in_feature_index]\n",
    "\n",
    "    label_name = [dataset.data_column_name[i] for i in config.label_in_feature_index]\n",
    "    label_column_num = len(config.label_columns)\n",
    "\n",
    "    loss = np.mean((label_data[config.predict_day:] - predict_data[:-config.predict_day] ) ** 2, axis=0)\n",
    "    loss_norm = loss/(dataset.std[config.label_in_feature_index] ** 2)\n",
    "    print(\"The mean squared error of stock {} is \".format(label_name) + str(loss_norm))\n",
    "\n",
    "    label_X = range(dataset.data_num - dataset.train_num - dataset.start_num_in_test)\n",
    "    predict_X = [ x + config.predict_day for x in label_X]\n",
    "\n",
    "    for i in range(label_column_num):\n",
    "        print(\"The predicted stock {} for the next {} day(s) is: \".format(label_name[i], config.predict_day) + str(np.squeeze(predict_data[-config.predict_day:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "34127c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(Module):\n",
    "    def __init__(self, input_size, hidden_size, layers, output_size, dropout_rate):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        #h0 = torch.zeros(self.layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "        gru_out, hidden = self.gru(x, hidden)\n",
    "        out = self.fc(gru_out) \n",
    "        return out, hidden\n",
    "\n",
    "def train(config, train_and_valid_data):\n",
    "    \n",
    "    train_X, train_Y, valid_X, valid_Y = train_and_valid_data\n",
    "    \n",
    "    train_X, train_Y = torch.from_numpy(train_X).float(), torch.from_numpy(train_Y).float() # To Tensor\n",
    "    train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=config.batch_size, drop_last=True)\n",
    "    \n",
    "    valid_X, valid_Y = torch.from_numpy(valid_X).float(), torch.from_numpy(valid_Y).float() #To Tensor\n",
    "    valid_loader = DataLoader(TensorDataset(valid_X, valid_Y), batch_size=config.batch_size, drop_last=True)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = GRU(config.input_size, config.hidden_size, config.layers, config.output_size, config.dropout_rate).to(device)\n",
    "    \n",
    "    optimizer =  torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    valid_loss_min = float(\"inf\")\n",
    "    bad_epoch = 0\n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(config.epoch):\n",
    "        print(\"Epoch {}/{}\".format(epoch, config.epoch))\n",
    "        model.train()\n",
    "        train_loss_array = []\n",
    "        hidden_train = None\n",
    "        for i, _data in enumerate(train_loader):\n",
    "            _train_X, _train_Y = _data[0].to(device),_data[1].to(device)\n",
    "            optimizer.zero_grad()               \n",
    "            pred_Y, hidden_train = model(_train_X, hidden_train)    \n",
    "\n",
    "            if not config.do_continue_train:\n",
    "                hidden_train = None\n",
    "            else:\n",
    "                h_0, c_0 = hidden_train\n",
    "                h_0.detach_(), c_0.detach_()    \n",
    "                hidden_train = (h_0, c_0)\n",
    "            loss = criterion(pred_Y, _train_Y)  \n",
    "            loss.backward()                     \n",
    "            optimizer.step()                    \n",
    "            train_loss_array.append(loss.item())\n",
    "            global_step += 1\n",
    "            if config.do_train_visualized and global_step % 100 == 0: \n",
    "                vis.line(X=np.array([global_step]), Y=np.array([loss.item()]), win='Train_Loss',\n",
    "                         update='append' if global_step > 0 else None, name='Train', opts=dict(showlegend=True))\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss_array = []\n",
    "        hidden_valid = None\n",
    "        for _valid_X, _valid_Y in valid_loader:\n",
    "            _valid_X, _valid_Y = _valid_X.to(device), _valid_Y.to(device)\n",
    "            pred_Y, hidden_valid = model(_valid_X, hidden_valid)\n",
    "            if not config.do_continue_train: hidden_valid = None\n",
    "            loss = criterion(pred_Y, _valid_Y)  \n",
    "            valid_loss_array.append(loss.item())\n",
    "\n",
    "        train_loss_cur = np.mean(train_loss_array)\n",
    "        valid_loss_cur = np.mean(valid_loss_array)\n",
    "        print(\"The train loss is {:.6f}. \".format(train_loss_cur) +\n",
    "              \"The valid loss is {:.6f}.\".format(valid_loss_cur))\n",
    "        if config.do_train_visualized:      \n",
    "            vis.line(X=np.array([epoch]), Y=np.array([train_loss_cur]), win='Epoch_Loss',\n",
    "                     update='append' if epoch > 0 else None, name='Train', opts=dict(showlegend=True))\n",
    "            vis.line(X=np.array([epoch]), Y=np.array([valid_loss_cur]), win='Epoch_Loss',\n",
    "                     update='append' if epoch > 0 else None, name='Eval', opts=dict(showlegend=True))\n",
    "\n",
    "        if valid_loss_cur < valid_loss_min:\n",
    "            valid_loss_min = valid_loss_cur\n",
    "            bad_epoch = 0\n",
    "            torch.save(model.state_dict(), config.model_save_path + \"GRU_model.pth\")\n",
    "        else:\n",
    "            bad_epoch += 1\n",
    "            if bad_epoch >= config.patience:    # Stop training if bad epoch\n",
    "                print(\" The training stops early in epoch {}\".format(epoch))\n",
    "                break\n",
    "\n",
    "def predict(config, test_X):\n",
    "\n",
    "    test_X = torch.from_numpy(test_X).float()\n",
    "    test_set = TensorDataset(test_X)\n",
    "    test_loader = DataLoader(test_set, batch_size=1)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = GRU(config.input_size, config.hidden_size, config.layers, config.output_size, config.dropout_rate).to(device)\n",
    "    model.load_state_dict(torch.load(config.model_save_path + \"GRU_model.pth\"))\n",
    "\n",
    "    result = torch.Tensor().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    hidden_predict = None\n",
    "    for _data in test_loader:\n",
    "        data_X = _data[0].to(device)\n",
    "        pred_X, hidden_predict = model(data_X, hidden_predict)\n",
    "        # if not config.do_continue_train: hidden_predict = None \n",
    "        cur_pred = torch.squeeze(pred_X, dim=0)\n",
    "        result = torch.cat((result, cur_pred), dim=0)\n",
    "\n",
    "    return result.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "51b2d6b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100\n",
      "The train loss is 0.158197. The valid loss is 0.045763.\n",
      "Epoch 1/100\n",
      "The train loss is 0.034495. The valid loss is 0.020456.\n",
      "Epoch 2/100\n",
      "The train loss is 0.018915. The valid loss is 0.012452.\n",
      "Epoch 3/100\n",
      "The train loss is 0.012451. The valid loss is 0.008010.\n",
      "Epoch 4/100\n",
      "The train loss is 0.008800. The valid loss is 0.005215.\n",
      "Epoch 5/100\n",
      "The train loss is 0.006640. The valid loss is 0.003574.\n",
      "Epoch 6/100\n",
      "The train loss is 0.005124. The valid loss is 0.002622.\n",
      "Epoch 7/100\n",
      "The train loss is 0.004280. The valid loss is 0.002135.\n",
      "Epoch 8/100\n",
      "The train loss is 0.003652. The valid loss is 0.001839.\n",
      "Epoch 9/100\n",
      "The train loss is 0.003334. The valid loss is 0.001676.\n",
      "Epoch 10/100\n",
      "The train loss is 0.003115. The valid loss is 0.001598.\n",
      "Epoch 11/100\n",
      "The train loss is 0.002984. The valid loss is 0.001628.\n",
      "Epoch 12/100\n",
      "The train loss is 0.002760. The valid loss is 0.001456.\n",
      "Epoch 13/100\n",
      "The train loss is 0.002604. The valid loss is 0.001456.\n",
      "Epoch 14/100\n",
      "The train loss is 0.002543. The valid loss is 0.001401.\n",
      "Epoch 15/100\n",
      "The train loss is 0.002447. The valid loss is 0.001464.\n",
      "Epoch 16/100\n",
      "The train loss is 0.002436. The valid loss is 0.001396.\n",
      "Epoch 17/100\n",
      "The train loss is 0.002292. The valid loss is 0.001373.\n",
      "Epoch 18/100\n",
      "The train loss is 0.002309. The valid loss is 0.001387.\n",
      "Epoch 19/100\n",
      "The train loss is 0.002229. The valid loss is 0.001373.\n",
      "Epoch 20/100\n",
      "The train loss is 0.002122. The valid loss is 0.001307.\n",
      "Epoch 21/100\n",
      "The train loss is 0.002166. The valid loss is 0.001328.\n",
      "Epoch 22/100\n",
      "The train loss is 0.002066. The valid loss is 0.001263.\n",
      "Epoch 23/100\n",
      "The train loss is 0.002110. The valid loss is 0.001241.\n",
      "Epoch 24/100\n",
      "The train loss is 0.002045. The valid loss is 0.001327.\n",
      "Epoch 25/100\n",
      "The train loss is 0.001973. The valid loss is 0.001188.\n",
      "Epoch 26/100\n",
      "The train loss is 0.001932. The valid loss is 0.001190.\n",
      "Epoch 27/100\n",
      "The train loss is 0.001938. The valid loss is 0.001222.\n",
      "Epoch 28/100\n",
      "The train loss is 0.001835. The valid loss is 0.001244.\n",
      "Epoch 29/100\n",
      "The train loss is 0.001807. The valid loss is 0.001156.\n",
      "Epoch 30/100\n",
      "The train loss is 0.001797. The valid loss is 0.001220.\n",
      "Epoch 31/100\n",
      "The train loss is 0.001762. The valid loss is 0.001133.\n",
      "Epoch 32/100\n",
      "The train loss is 0.001739. The valid loss is 0.001117.\n",
      "Epoch 33/100\n",
      "The train loss is 0.001714. The valid loss is 0.001118.\n",
      "Epoch 34/100\n",
      "The train loss is 0.001655. The valid loss is 0.001178.\n",
      "Epoch 35/100\n",
      "The train loss is 0.001678. The valid loss is 0.001075.\n",
      "Epoch 36/100\n",
      "The train loss is 0.001621. The valid loss is 0.001203.\n",
      "Epoch 37/100\n",
      "The train loss is 0.001664. The valid loss is 0.001101.\n",
      "Epoch 38/100\n",
      "The train loss is 0.001674. The valid loss is 0.001051.\n",
      "Epoch 39/100\n",
      "The train loss is 0.001599. The valid loss is 0.001244.\n",
      "Epoch 40/100\n",
      "The train loss is 0.001633. The valid loss is 0.001033.\n",
      "Epoch 41/100\n",
      "The train loss is 0.001592. The valid loss is 0.001097.\n",
      "Epoch 42/100\n",
      "The train loss is 0.001571. The valid loss is 0.001021.\n",
      "Epoch 43/100\n",
      "The train loss is 0.001538. The valid loss is 0.001040.\n",
      "Epoch 44/100\n",
      "The train loss is 0.001560. The valid loss is 0.001116.\n",
      "Epoch 45/100\n",
      "The train loss is 0.001551. The valid loss is 0.001085.\n",
      "Epoch 46/100\n",
      "The train loss is 0.001598. The valid loss is 0.001149.\n",
      "Epoch 47/100\n",
      "The train loss is 0.001632. The valid loss is 0.001087.\n",
      " The training stops early in epoch 47\n",
      "The mean squared error of stock ['QQQ_High', 'QQQ_Low'] is [0.01011448 0.01628662]\n",
      "The predicted stock QQQ_High for the next 1 day(s) is: 362.64000071261904\n",
      "The predicted stock QQQ_Low for the next 1 day(s) is: 354.67760490471983\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9573a244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(vars(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d808f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274e507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b26c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
